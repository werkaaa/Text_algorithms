{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex match and search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weronika Ormaniec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do wyszukiwania wyrażeń regularnych wykorzystano niedeterministyczny automat skończony i równoległe przeszukiwanie jego stanów zgodnie z algorytmem Thompsona. Zaimplementowano funkcje *match* i *search*. *match* sprawdza, czy dane słowo spełnia wyrażenie regularne natomiast *search* znajduje końce wystąpień wyrażenia regularnego w dłuższym tekście."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, c_=-1, s_ = None, out_ = None, out1_ = None, lastlist_ = None):\n",
    "        self.c = c_\n",
    "        self.s = s_\n",
    "        self.out = out_ \n",
    "        self.out1 = out1_ \n",
    "        self.lastlist = lastlist_\n",
    "        self.parent = None\n",
    "        self.visited = True\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.c==0:\n",
    "            return f'|{self.s}, {id(self)}, {id(self.out)}, {id(self.out1)}|'\n",
    "        else:\n",
    "            return f'|{self.c}, {id(self)}, {id(self.out)}, {id(self.out1)}|'\n",
    "\n",
    "class NFA_fragment:\n",
    "    def __init__(self, start_=None, out_=[]):\n",
    "        self.start = start_\n",
    "        self.out = out_\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'start: {self.start}, out: {self.out}'\n",
    "        \n",
    "def patch(list_of_ends, node):\n",
    "    for end_pointer in list_of_ends:\n",
    "        if end_pointer.parent.out is end_pointer:\n",
    "            end_pointer.parent.out = node\n",
    "        elif end_pointer.parent.out1 is end_pointer:\n",
    "            end_pointer.parent.out1 = node\n",
    "    return list_of_ends\n",
    "        \n",
    "def postfix_to_NFA(postfix):\n",
    "    stack = []\n",
    "    alphabet = string.ascii_letters + string.digits + string.whitespace + '.'\n",
    "    \n",
    "    i = 0\n",
    "    while i <len(postfix):\n",
    "        letter = postfix[i]\n",
    "        if letter in alphabet:\n",
    "            s = State(c_=0, s_=letter, out_=State(), out1_=State())\n",
    "            s.out.parent = s\n",
    "            s.out1.parent = s\n",
    "            stack.append(NFA_fragment(start_=s, out_=[s.out]))\n",
    "        elif letter == '?':\n",
    "            e = stack.pop()\n",
    "            s = State(c_='Split', out_=e.start, out1_=State())\n",
    "            s.out.parent = s\n",
    "            s.out1.parent = s\n",
    "            stack.append(NFA_fragment(start_=s, out_=e.out+[s.out1]))\n",
    "        elif letter == '*':\n",
    "            e = stack.pop()\n",
    "            s = State(c_='Split', out_=e.start, out1_=State())\n",
    "            s.out.parent = s\n",
    "            s.out1.parent = s\n",
    "            patch(e.out, s)\n",
    "            stack.append(NFA_fragment(start_=s, out_=[s.out1]))\n",
    "        elif letter == '+':\n",
    "            e = stack.pop()\n",
    "            s = State(c_='Split', out_=e.start, out1_=State())\n",
    "            s.out.parent = s\n",
    "            s.out1.parent = s\n",
    "            patch(e.out, s)\n",
    "            stack.append(NFA_fragment(start_=e.start, out_=[s.out1]))\n",
    "        elif letter == '_':\n",
    "            e2 = stack.pop()\n",
    "            e1 = stack.pop()\n",
    "            e1.out = patch(e1.out, e2.start)\n",
    "            stack.append(NFA_fragment(start_=e1.start, out_=e2.out))\n",
    "        elif letter == '|':\n",
    "            e2 = stack.pop()\n",
    "            e1 = stack.pop()\n",
    "            s = State(c_='Split', out_=e1.start, out1_=e2.start)\n",
    "            stack.append(NFA_fragment(start_=s, out_=e1.out+e2.out))\n",
    "        elif letter == '[':\n",
    "            category = \"\"\n",
    "            i += 1\n",
    "            while postfix[i] != ']':\n",
    "                category += postfix[i]\n",
    "                i+=1\n",
    "            s = State(c_=0, s_=category, out_=State(), out1_=State())\n",
    "            s.out.parent = s\n",
    "            s.out1.parent = s\n",
    "            stack.append(NFA_fragment(start_=s, out_=[s.out]))\n",
    "        elif letter == '\\\\':\n",
    "            i += 1\n",
    "            if postfix[i] == 's':\n",
    "                category = string.ascii_letters\n",
    "            elif postfix[i] == 'd':\n",
    "                category = string.digits\n",
    "            elif postfix[i] == 'w':\n",
    "                category = string.whitespace\n",
    "            s = State(c_=0, s_=category, out_=State(), out1_=State())\n",
    "            s.out.parent = s\n",
    "            s.out1.parent = s\n",
    "            stack.append(NFA_fragment(start_=s, out_=[s.out]))\n",
    "        i += 1\n",
    "\n",
    "    e = stack.pop()\n",
    "    matchstate = State(c_='Match')\n",
    "    \n",
    "    patch(e.out, matchstate)\n",
    "    return e.start\n",
    "\n",
    "def ismatch(some_list):\n",
    "    for state in some_list:\n",
    "        if state.c == 'Match':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def dfs_set(node, condition):\n",
    "    if node is not None and node.visited == condition:\n",
    "        node.lastlist = None\n",
    "        node.visited = not condition\n",
    "        dfs_set(node.out, condition)\n",
    "        dfs_set(node.out1, condition)\n",
    "    \n",
    "def match(start, text):\n",
    "    dfs_set(start, start.visited)\n",
    "    clist = []\n",
    "    nlist = []\n",
    "    listid = 1\n",
    "    clist = add_state(clist, start, listid)\n",
    "    \n",
    "    for letter in text:\n",
    "        nlist, listid = step(clist, letter, nlist, listid)\n",
    "        clist, nlist = nlist, clist\n",
    "        if len(clist)==0:\n",
    "            return False\n",
    "        \n",
    "    return ismatch(clist)\n",
    "\n",
    "def add_state(some_list, state, listid):\n",
    "    if state.c == 'Split':\n",
    "        if state.out.lastlist != listid:\n",
    "            state.out.lastlist = listid\n",
    "            some_list.append(state.out)\n",
    "            \n",
    "        if state.out1.lastlist != listid:\n",
    "            state.out1.lastlist = listid\n",
    "            some_list.append(state.out1)\n",
    "    else:\n",
    "        if state.lastlist != listid:\n",
    "            state.lastlist = listid\n",
    "            some_list.append(state)\n",
    "    return some_list\n",
    "    \n",
    "    \n",
    "def step(clist, letter, nlist, listid):\n",
    "    listid+=1\n",
    "    nlist = []\n",
    "    for state in clist:\n",
    "        if state.s is not None and (letter in state.s or state.s == '.'):\n",
    "            nlist = add_state(nlist, state.out, listid)\n",
    "            \n",
    "    return nlist, listid\n",
    "\n",
    "def infix_to_postfix(regex):\n",
    "    alphabet = string.ascii_letters + string.digits + string.whitespace + '.'\n",
    "    concat_added = \"\"\n",
    "    i = 0\n",
    "    in_brackets = False\n",
    "    while i < len(regex):\n",
    "        letter = regex[i]\n",
    "        if letter == '[': \n",
    "            in_brackets = not in_brackets\n",
    "            if len(concat_added)>0:\n",
    "                concat_added += '_'\n",
    "        elif letter == ']':\n",
    "            in_brackets = not in_brackets\n",
    "        elif letter == '\\\\':\n",
    "            if len(concat_added)>0:\n",
    "                concat_added += '_'\n",
    "            concat_added += regex[i:i+2]\n",
    "            i += 2\n",
    "            continue\n",
    "        elif concat_added == \"\":\n",
    "            concat_added = letter\n",
    "            i+= 1\n",
    "            continue\n",
    "        elif (not in_brackets and \n",
    "        ((letter in alphabet and (concat_added[-1] in alphabet or concat_added[-1] in ['*', '+', '?', ']'])) or\n",
    "                                  (letter in ['('] and concat_added[-1] in alphabet))):\n",
    "            concat_added += '_'\n",
    "        concat_added += letter\n",
    "        i += 1\n",
    "    regex = concat_added\n",
    "    \n",
    "    stack = []\n",
    "    postfix = \"\"\n",
    "    precedense = {'|':1, '_':2, '?':3, '+':3, '*':3}\n",
    "    i = 0\n",
    "    while i < len(regex):\n",
    "        letter = regex[i]\n",
    "        if letter in alphabet:\n",
    "            postfix += letter\n",
    "        elif letter == ')':\n",
    "            while stack[-1] != '(':\n",
    "                operand = stack.pop()\n",
    "                postfix += operand\n",
    "            stack.pop()\n",
    "        elif letter == '(':\n",
    "            stack.append('(')\n",
    "        elif letter in precedense.keys():\n",
    "            while len(stack)>0 and stack[-1]!='(' and precedense[stack[-1]]>=precedense[letter]:\n",
    "                operand = stack.pop()\n",
    "                postfix += operand\n",
    "            stack.append(letter)\n",
    "        elif letter=='[':\n",
    "            postfix += letter\n",
    "            i += 1\n",
    "            while regex[i] != ']':\n",
    "                postfix += regex[i]\n",
    "                i += 1\n",
    "            postfix += regex[i]\n",
    "        elif letter == '\\\\':\n",
    "            postfix += regex[i:i+2]\n",
    "            i += 1\n",
    "        i += 1\n",
    "            \n",
    "    while len(stack)>0:\n",
    "        operand = stack.pop()\n",
    "        postfix += operand\n",
    "\n",
    "    return postfix\n",
    "\n",
    "def regex_to_NFA(regex):\n",
    "    postfix = infix_to_postfix(regex)\n",
    "    return postfix_to_NFA(postfix)\n",
    "            \n",
    "def add_state(some_list, state, listid):\n",
    "    if state.c == 'Split':\n",
    "        if state.out.lastlist != listid:\n",
    "            state.out.lastlist = listid\n",
    "            some_list.append(state.out)\n",
    "            \n",
    "        if state.out1.lastlist != listid:\n",
    "            state.out1.lastlist = listid\n",
    "            some_list.append(state.out1)\n",
    "        \n",
    "    else:\n",
    "        if state.lastlist != listid:\n",
    "            state.lastlist = listid\n",
    "            some_list.append(state)\n",
    "           \n",
    "    return some_list\n",
    "\n",
    "            \n",
    "def search_step(clist, letter, nlist, listid, output, start):\n",
    "    listid+=1\n",
    "    nlist = []\n",
    "    if start.c == 'Split' or (start.s is not None and (letter in start.s or start.s == '.')):\n",
    "        clist = add_state(clist, start, listid)\n",
    "    for state in clist:\n",
    "        if state.s is not None and (letter in state.s or state.s == '.'):\n",
    "            nlist = add_state(nlist, state.out, listid) \n",
    "            if state.out.c == 'Match' or (state.out.c == 'Split' and (state.out.out.c == 'Match' or\n",
    "                                                                      state.out.out1.c == 'Match')):\n",
    "                \n",
    "                output.append(listid-1)\n",
    "\n",
    "    return nlist, listid, output\n",
    "    \n",
    "def search(start,text):\n",
    "    dfs_set(start, start.visited)\n",
    "    clist = []\n",
    "    nlist = []\n",
    "    listid = 0\n",
    "    output = []\n",
    "    \n",
    "    for letter in text:\n",
    "        nlist, listid, output = search_step(clist, letter, nlist, listid, output, start)\n",
    "        clist, nlist = nlist, clist\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prosty wzorzec bez znaków specjalnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: True\n",
      "Match: False\n",
      "End of regex found at: [17]\n",
      "algorytmy tekstowe\n"
     ]
    }
   ],
   "source": [
    "NFA = regex_to_NFA('algorytmy tekstowe')\n",
    "print(f'Match: {match(NFA, \"algorytmy tekstowe\")}')\n",
    "print(f'Match: {match(NFA, \"algorytmy\")}')\n",
    "text = \"algorytmy tekstowe sa fajne\"\n",
    "found = search(NFA, text)\n",
    "print(f'End of regex found at: {found}')\n",
    "for f in found:\n",
    "      print(text[:f+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wzorzec z '.' zamiast dowolnego znaku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: True\n",
      "Match: False\n",
      "End of regex found at: [17]\n",
      "algorytmy tekstoze\n"
     ]
    }
   ],
   "source": [
    "NFA = regex_to_NFA('algorytmy teksto.e')\n",
    "print(f'Match: {match(NFA, \"algorytmy tekstome\")}')\n",
    "print(f'Match: {match(NFA, \"algorytmy\")}')\n",
    "text = \"algorytmy tekstoze sa fajne\"\n",
    "found = search(NFA, text)\n",
    "print(f'End of regex found at: {found}')\n",
    "for f in found:\n",
    "      print(text[:f+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operatory '*', '+', '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: True\n",
      "Match: True\n",
      "Match: False\n",
      "End of regex found at: [22, 52]\n",
      "aaaalgorytmy tekstooowe\n",
      "aaaalgorytmy tekstooowe sa fajne ale lgorytm tekstowe\n"
     ]
    }
   ],
   "source": [
    "NFA = regex_to_NFA('a*lgorytmy? teksto+we')\n",
    "print(f'Match: {match(NFA, \"aaaalgorytmy tekstooowe\")}')\n",
    "print(f'Match: {match(NFA, \"lgorytm tekstowe\")}')\n",
    "print(f'Match: {match(NFA, \"lgorytm tekstwe\")}')\n",
    "text = \"aaaalgorytmy tekstooowe sa fajne ale lgorytm tekstowe bywaja trudne\"\n",
    "found = search(NFA, text)\n",
    "print(f'End of regex found at: {found}')\n",
    "for f in found:\n",
    "      print(text[:f+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wzorce z nawiasami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: True\n",
      "Match: True\n",
      "Match: False\n",
      "End of regex found at: [23, 49]\n",
      "alglgoalgorytmy tekstowe\n",
      "alglgoalgorytmy tekstowe sa fajne ale rytmy tekste\n"
     ]
    }
   ],
   "source": [
    "NFA = regex_to_NFA('(a(lg)+o)*rytmy tekst(ow)?e')\n",
    "print(f'Match: {match(NFA, \"alglgoalgorytmy tekstowe\")}')\n",
    "print(f'Match: {match(NFA, \"rytmy tekste\")}')\n",
    "print(f'Match: {match(NFA, \"lgorytm tekstwe\")}')\n",
    "text = \"alglgoalgorytmy tekstowe sa fajne ale rytmy tekste bywaja trudne\"\n",
    "found = search(NFA, text)\n",
    "print(f'End of regex found at: {found}')\n",
    "for f in found:\n",
    "      print(text[:f+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupy znaków w '[]' i klasy znaków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: True\n",
      "Match: True\n",
      "Match: False\n",
      "End of regex found at: [18, 53]\n",
      "algorytmy tekstowe1\n",
      "algorytmy tekstowe1 sa fajne ale algorytmy tekstoewwe1\n"
     ]
    }
   ],
   "source": [
    "NFA = regex_to_NFA('algo\\sytmy\\wtekst[owe3]*we\\d')\n",
    "print(f'Match: {match(NFA, \"algorytmy tekstowe1\")}')\n",
    "print(f'Match: {match(NFA, \"algorytmy tekstoewwe1\")}')\n",
    "print(f'Match: {match(NFA, \"algo4ytmy tekstowe4\")}')\n",
    "text = \"algorytmy tekstowe1 sa fajne ale algorytmy tekstoewwe1 bywaja trudne\"\n",
    "found = search(NFA, text)\n",
    "print(f'End of regex found at: {found}')\n",
    "for f in found:\n",
    "      print(text[:f+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
